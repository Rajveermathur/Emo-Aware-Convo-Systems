{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57166ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f08a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6060b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaebe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from uuid import uuid4\n",
    "\n",
    "def make_chunks(chat_data):\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(chat_data):\n",
    "        if chat_data[i][\"speaker\"] == \"Human\":\n",
    "            human_msg = chat_data[i][\"message\"]\n",
    "            ai_msg = chat_data[i + 1][\"message\"] if (i + 1 < len(chat_data) and chat_data[i + 1][\"speaker\"] == \"AI\") else \"\"\n",
    "            \n",
    "            chunk = {\n",
    "                \"id\": f\"turn_{i}_{uuid4().hex[:6]}\",\n",
    "                \"text\": human_msg.strip(),\n",
    "                \"metadata\": {\n",
    "                    \"speaker\": \"human\",\n",
    "                    \"ai_reply\": ai_msg.strip(),\n",
    "                    \"turn_number\": i,\n",
    "                    \"emotion\": None,   # placeholder for future tagging\n",
    "                    \"topic\": None\n",
    "                }\n",
    "            }\n",
    "            chunks.append(chunk)\n",
    "        i += 1\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example\n",
    "with open(\"chat.json\", \"r\") as f:\n",
    "    chat_data = json.load(f)\n",
    "\n",
    "chunks = make_chunks(chat_data)\n",
    "\n",
    "with open(\"chunks_ready.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=2)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec143204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 chunks âœ…\n",
      "{'id': 'turn_0_430ba2', 'text': 'Iâ€™ve been feeling off lately, like Iâ€™m just going through the motions every day.', 'metadata': {'speaker': 'human', 'ai_reply': 'That sounds really hard. When life starts feeling repetitive or dull, itâ€™s often a sign your mind needs a break or some new stimulus. Can you tell me whatâ€™s been draining you lately?', 'turn_number': 0, 'emotion': 'test', 'topic': 'test'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"chunks_ready.json\", \"r\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(chunks)} chunks âœ…\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d451b540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to persistent Chroma collection.\n",
      "â„¹ï¸ No new chunks to add. Database already up-to-date.\n",
      "\n",
      "ðŸ” Top Matches:\n",
      "\n",
      "ðŸ—£ï¸ Human said: Iâ€™ve been feeling off lately, like Iâ€™m just going through the motions every day.\n",
      "ðŸ¤– AI replied: That sounds really hard. When life starts feeling repetitive or dull, itâ€™s often a sign your mind needs a break or some new stimulus. Can you tell me whatâ€™s been draining you lately?\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from uuid import uuid4\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------- STEP 3: Initialize persistent Chroma ----------\n",
    "# Create persistent directory\n",
    "persist_dir = \"./chroma_store\"\n",
    "os.makedirs(persist_dir, exist_ok=True)\n",
    "\n",
    "# Persistent client\n",
    "client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\"mental_health_chat\")\n",
    "print(\"âœ… Connected to persistent Chroma collection.\")\n",
    "\n",
    "\n",
    "# ---------- STEP 4: Generate embeddings ----------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "ids = [c[\"id\"] for c in chunks]\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "metadatas = [c[\"metadata\"] for c in chunks]\n",
    "\n",
    "embeddings = model.encode(texts).tolist()\n",
    "\n",
    "# ---------- STEP 5: Add to Chroma (if not already present) ----------\n",
    "existing_ids = set(collection.get(ids=ids).get(\"ids\", []))\n",
    "new_chunks = [(i, t, m, e) for i, t, m, e in zip(ids, texts, metadatas, embeddings) if i not in existing_ids]\n",
    "\n",
    "if new_chunks:\n",
    "    collection.add(\n",
    "        ids=[i for i, _, _, _ in new_chunks],\n",
    "        documents=[t for _, t, _, _ in new_chunks],\n",
    "        metadatas=[m for _, _, m, _ in new_chunks],\n",
    "        embeddings=[e for _, _, _, e in new_chunks],\n",
    "    )\n",
    "    print(f\"âœ… Added {len(new_chunks)} new chunks to persistent Chroma.\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No new chunks to add. Database already up-to-date.\")\n",
    "\n",
    "\n",
    "# ---------- STEP 6: Example Query ----------\n",
    "query = \"I keep feeling tired and unmotivated lately.\"\n",
    "query_emb = model.encode([query]).tolist()\n",
    "\n",
    "results = collection.query(query_embeddings=query_emb, n_results=1, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "\n",
    "print(\"\\nðŸ” Top Matches:\")\n",
    "for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "    print(f\"\\nðŸ—£ï¸ Human said: {doc}\")\n",
    "    print(f\"ðŸ¤– AI replied: {meta['ai_reply']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d359044",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf36dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key='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')\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
